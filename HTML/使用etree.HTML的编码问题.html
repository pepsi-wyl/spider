 
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
    </head>
    <body>
    <p class="site-subtitle">给时光以生命。</p> <p>今天指导一个学生爬取新浪体育手机版的时候，发现lxml.etree.HTML处理网页源代码会默认修改编码，导致打印出来的内容为乱码。爬取的网址为：<a href="http://sports.sina.cn/nba/rockets/2015-10-07/detail-ifximrxn8235561.d.html?vt=4&amp;pos=10" rel="noopener" target="_blank" title="http://sports.sina.cn/nba/rockets/2015-10-07/detail-ifximrxn8235561.d.html?vt=4&amp;pos=10">http://sports.sina.cn/nba/rockets/2015-10-07/detail-ifximrxn8235561.d.html?vt=4&amp;pos=10</a></p> <p>首先导入我们需要用到的库文件，然后设置环境：</p> <p>然后获取网页的源代码：<br/><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/></pre></td><td class="code"><pre><span class="line"></span><br/><span class="line">r = requests.get(url='http://sports.sina.cn/nba/rockets/2015-10-07/detail-ifximrxn8235561.d.html?vt=4&amp;pos=10')# 最基本的GET请求</span><br/><span class="line">r.encoding = 'utf-8'</span><br/><span class="line">r = r.content</span><br/><span class="line">print r</span><br/></pre></td></tr></table></figure></p> <p>打印出网页源代码，发现中文是乱码，如图：</p> <p><img alt="" src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding1.gif"/></p> <p>这是小问题，使用<a href="http://blog.kingname.info/2014/12/14/Python%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E7%9A%84%E4%B8%80%E4%B8%AA%E7%9B%B8%E5%AF%B9%E4%B8%87%E8%83%BD%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/" rel="noopener" target="_blank">Python字符编码的一个相对万能的处理方法</a>这篇文章中讲解的方法，轻松解决。</p> <p>将：<br/><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">r = r.content</span><br/></pre></td></tr></table></figure></p> <p>修改为:<br/><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">r = r.content.decode('utf-8').encode('gbk')</span><br/></pre></td></tr></table></figure></p> <p>可以正常显示中文，如图：<br/><img alt="" src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding2.png"/></p> <p>接下来，使用etree.HTML处理源代码，然后使用Xpath提取内容，一切似乎看起来轻车熟路。</p> <p><img alt="" src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding3.png"/></p> <p>但是当我打印出来，才发现问题没有这么简单。如图：</p> <p><img alt="" src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding4.png"/></p> <p>这个时候，我发现使用<a href="http://blog.kingname.info/2014/12/14/Python%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E7%9A%84%E4%B8%80%E4%B8%AA%E7%9B%B8%E5%AF%B9%E4%B8%87%E8%83%BD%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/" rel="noopener" target="_blank">Python字符编码的一个相对万能的处理方法</a>讲到的办法已经不能解决问题了。</p> <p>通过调试，我发现抓取到的内容是乱码：</p> <p><img alt="" src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding5.png"/></p> <p>使用Scrapy的Xpath，正常提取需要的内容：</p> <p><img alt="" src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding6.png"/></p> <p>实际上，Scrapy的Xpath底层还是调用的lxml那为什么它可以，而我直接使用lxml的etree.HTML处理源代码然后Xpath提取内容就出乱码呢？</p> <p>显然这应该是编码的问题，在使用:</p> <p>处理源文件的时候，由于没有指定编码，所以它使用了一个默认编码，从而导致和UTF-8冲突，产生乱码。</p> <p>经过查阅lxml.etree.HTML的文档，我发现etree.HTML有一个参数是parser这个参数不是必须的，因此省略以后它就会自动使用一个默认的parser。既然如此，那我手动指定一个：</p> <p>这里我指定了etree.HTMLParser来作为一个parser同时，etree.HTMLParser可以接受编码作为参数。于是我指定为UTF-8。</p> <p>运行看看效果：</p> <p><img alt="" src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding7.png"/></p> <p>继续报错，但是出错信息改变了，提示utf8不能解码。请注意第11行，现在源代码是gbk编码，所以使用UTF-8不能解码。于是可以把第11行重新改回原来的样子：</p> <p>再一次运行，发现正常抓取信息：</p> <p><img alt="" src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding8.png"/></p> <p>这一次的问题提示我们：遇到问题，通过经验解决不了的时候，请回归文档。</p> <p><em>原文发表在：<a href="http://blog.kingname.info/2015/10/07/lxmlencoding/" rel="noopener" target="_blank">http://blog.kingname.info/2015/10/07/lxmlencoding/</a>转载请注明出处！</em></p> <p class="site-author-name" itemprop="name">谢乾坤 | Kingname</p> <p class="site-description motion-element" itemprop="description">高级数据挖掘工程师，《Python 爬虫开发 从入门到实战》、《左手 MongoDB 右手 Redis——从入门到商业实战》作者。 微软最有价值专家 MVP，Python Scrapy MongoDB Redis Pandas Golang。</p>
    </body>
    </html>
    